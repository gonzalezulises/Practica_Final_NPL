# An√°lisis de Sentimiento de Rese√±as de Productos de Amazon

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Libraries](https://img.shields.io/badge/Librer√≠as-Scikit--learn%20%7C%20Pandas%20%7C%20NLTK-orange.svg)
![License](https://img.shields.io/badge/Licencia-MIT-green.svg)

Este repositorio contiene un proyecto completo de Procesamiento de Lenguaje Natural (NLP) enfocado en la clasificaci√≥n de sentimiento (positivo vs. negativo) de rese√±as de productos de Amazon. El proyecto abarca todas las etapas de un flujo de trabajo de Machine Learning, desde la exploraci√≥n inicial de los datos hasta la evaluaci√≥n y conclusi√≥n de un modelo final.

## üìù Descripci√≥n del Proyecto

El objetivo principal es construir y evaluar un clasificador de sentimiento utilizando un enfoque de clasificaci√≥n binaria supervisada. El proyecto se centra no solo en el rendimiento final del modelo, sino tambi√©n en el an√°lisis, la justificaci√≥n de las decisiones t√©cnicas y la interpretaci√≥n de los resultados, siguiendo las directrices de una pr√°ctica realista de NLP.

---

## ‚ú® Caracter√≠sticas Principales

* **An√°lisis Exploratorio de Datos (EDA):**
    * An√°lisis de la distribuci√≥n de calificaciones para identificar la estructura de los datos.
    * Identificaci√≥n y visualizaci√≥n de un fuerte desbalanceo de clases.
    * Extracci√≥n y an√°lisis de N-grams (bigramas) para encontrar las frases m√°s comunes en cada sentimiento.
    * Generaci√≥n de nubes de palabras para visualizar los t√©rminos m√°s frecuentes.
    * Entrenamiento de un modelo Word2Vec y visualizaci√≥n de embeddings con t-SNE para explorar relaciones sem√°nticas.

* **Preprocesado de Texto:**
    * Creaci√≥n de una pipeline de limpieza robusta y encapsulada en una √∫nica funci√≥n.
    * Pasos incluidos: conversi√≥n a min√∫sculas, eliminaci√≥n de HTML/URLs, eliminaci√≥n de puntuaci√≥n y n√∫meros, tokenizaci√≥n, eliminaci√≥n de *stop words* y lematizaci√≥n.

* **Modelado y Evaluaci√≥n:**
    * Vectorizaci√≥n de texto usando **TF-IDF** con unigramas y bigramas.
    * Entrenamiento y comparaci√≥n de dos modelos: **Regresi√≥n Log√≠stica** y **Naive Bayes Multinomial**.
    * Aplicaci√≥n de la t√©cnica `class_weight='balanced'` para gestionar el desbalanceo de clases.
    * Evaluaci√≥n de modelos utilizando reportes de clasificaci√≥n (precisi√≥n, recall, f1-score) y matrices de confusi√≥n.

---

## üìä Dataset

El proyecto utiliza el dataset **"Automotive_5"** del conjunto de datos de rese√±as de productos de Amazon, recopilado por J. McAuley de la UCSD. Este es un dataset "5-core", lo que garantiza que cada usuario y producto tiene al menos cinco rese√±as.

* **Fuente:** [Amazon Review Data (2014)](http://jmcauley.ucsd.edu/data/amazon/)
* **Archivo:** `reviews_Automotive_5.json.gz`

---

## üöÄ Resultados Clave

El an√°lisis y modelado arrojaron dos conclusiones principales:

1.  **Fuerte Desbalanceo de Clases:** El an√°lisis exploratorio revel√≥ una proporci√≥n de rese√±as positivas a negativas de casi **16 a 1**. Este fue el desaf√≠o t√©cnico m√°s importante a superar.

2.  **Rendimiento del Modelo Final:** El modelo de **Regresi√≥n Log√≠stica** fue el claro ganador, principalmente por su capacidad para manejar el desbalanceo de clases. El modelo Naive Bayes, sin este ajuste, result√≥ in√∫til al predecir √∫nicamente la clase mayoritaria.

    **M√©tricas del Modelo de Regresi√≥n Log√≠stica (en el conjunto de prueba):**

    | M√©trica | Clase 'Negativo' | Clase 'Positivo' | General (Accuracy) |
    | :--- | :---: | :---: | :---: |
    | **Precision** | 0.35 | 0.98 | |
    | **Recall** | **0.65** | 0.92 | **0.91** |
    | **F1-Score** | 0.46 | 0.95 | |

    La m√©trica m√°s importante, el **recall de 0.65 para la clase negativa**, indica que el modelo es capaz de identificar correctamente el 65% de todas las quejas de los clientes, proporcionando un valor real para un caso de uso de negocio.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Lenguaje:** Python 3
* **Librer√≠as Principales:**
    * Pandas: Manipulaci√≥n y an√°lisis de datos.
    * Scikit-learn: Modelado de Machine Learning y m√©tricas.
    * NLTK: Preprocesado de texto (stop words, lematizaci√≥n).
    * Gensim: Modelado de t√≥picos (Word2Vec).
    * Matplotlib y Seaborn: Visualizaci√≥n de datos.
    * WordCloud: Creaci√≥n de nubes de palabras.
* **Entorno:** Jupyter Notebook (desarrollado en Google Colab).

---

## üìÇ Estructura del Repositorio

‚îú‚îÄ‚îÄ Pr√°ctica_final_NLP_Ulises_Gonz√°lez.ipynb
‚îî‚îÄ‚îÄ README.md
Of course. Here is the corrected and cleaned-up version of your Markdown text.

```markdown
# An√°lisis de Sentimiento de Rese√±as de Productos de Amazon

![Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Libraries](https://img.shields.io/badge/Librer√≠as-Scikit--learn%20%7C%20Pandas%20%7C%20NLTK-orange.svg)
![License](https://img.shields.io/badge/Licencia-MIT-green.svg)

Este repositorio contiene un proyecto completo de Procesamiento de Lenguaje Natural (NLP) enfocado en la clasificaci√≥n de sentimiento (positivo vs. negativo) de rese√±as de productos de Amazon. El proyecto abarca todas las etapas de un flujo de trabajo de Machine Learning, desde la exploraci√≥n inicial de los datos hasta la evaluaci√≥n y conclusi√≥n de un modelo final.

## üìù Descripci√≥n del Proyecto

El objetivo principal es construir y evaluar un clasificador de sentimiento utilizando un enfoque de clasificaci√≥n binaria supervisada. El proyecto se centra no solo en el rendimiento final del modelo, sino tambi√©n en el an√°lisis, la justificaci√≥n de las decisiones t√©cnicas y la interpretaci√≥n de los resultados, siguiendo las directrices de una pr√°ctica realista de NLP.

---

## ‚ú® Caracter√≠sticas Principales

* **An√°lisis Exploratorio de Datos (EDA):**
    * An√°lisis de la distribuci√≥n de calificaciones para identificar la estructura de los datos.
    * Identificaci√≥n y visualizaci√≥n de un fuerte desbalanceo de clases.
    * Extracci√≥n y an√°lisis de N-grams (bigramas) para encontrar las frases m√°s comunes en cada sentimiento.
    * Generaci√≥n de nubes de palabras para visualizar los t√©rminos m√°s frecuentes.
    * Entrenamiento de un modelo Word2Vec y visualizaci√≥n de embeddings con t-SNE para explorar relaciones sem√°nticas.

* **Preprocesado de Texto:**
    * Creaci√≥n de una pipeline de limpieza robusta y encapsulada en una √∫nica funci√≥n.
    * Pasos incluidos: conversi√≥n a min√∫sculas, eliminaci√≥n de HTML/URLs, eliminaci√≥n de puntuaci√≥n y n√∫meros, tokenizaci√≥n, eliminaci√≥n de *stop words* y lematizaci√≥n.

* **Modelado y Evaluaci√≥n:**
    * Vectorizaci√≥n de texto usando **TF-IDF** con unigramas y bigramas.
    * Entrenamiento y comparaci√≥n de dos modelos: **Regresi√≥n Log√≠stica** y **Naive Bayes Multinomial**.
    * Aplicaci√≥n de la t√©cnica `class_weight='balanced'` para gestionar el desbalanceo de clases.
    * Evaluaci√≥n de modelos utilizando reportes de clasificaci√≥n (precisi√≥n, recall, f1-score) y matrices de confusi√≥n.

---

## üìä Dataset

El proyecto utiliza el dataset **"Automotive_5"** del conjunto de datos de rese√±as de productos de Amazon, recopilado por J. McAuley de la UCSD. Este es un dataset "5-core", lo que garantiza que cada usuario y producto tiene al menos cinco rese√±as.

* **Fuente:** [Amazon Review Data (2014)](http://jmcauley.ucsd.edu/data/amazon/)
* **Archivo:** `reviews_Automotive_5.json.gz`

---

## üöÄ Resultados Clave

El an√°lisis y modelado arrojaron dos conclusiones principales:

1.  **Fuerte Desbalanceo de Clases:** El an√°lisis exploratorio revel√≥ una proporci√≥n de rese√±as positivas a negativas de casi **16 a 1**. Este fue el desaf√≠o t√©cnico m√°s importante a superar.

2.  **Rendimiento del Modelo Final:** El modelo de **Regresi√≥n Log√≠stica** fue el claro ganador, principalmente por su capacidad para manejar el desbalanceo de clases. El modelo Naive Bayes, sin este ajuste, result√≥ in√∫til al predecir √∫nicamente la clase mayoritaria.

    **M√©tricas del Modelo de Regresi√≥n Log√≠stica (en el conjunto de prueba):**

    | M√©trica | Clase 'Negativo' | Clase 'Positivo' | General (Accuracy) |
    | :--- | :---: | :---: | :---: |
    | **Precision** | 0.35 | 0.98 | |
    | **Recall** | **0.65** | 0.92 | **0.91** |
    | **F1-Score** | 0.46 | 0.95 | |

    La m√©trica m√°s importante, el **recall de 0.65 para la clase negativa**, indica que el modelo es capaz de identificar correctamente el 65% de todas las quejas de los clientes, proporcionando un valor real para un caso de uso de negocio.

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

* **Lenguaje:** Python 3
* **Librer√≠as Principales:**
    * Pandas: Manipulaci√≥n y an√°lisis de datos.
    * Scikit-learn: Modelado de Machine Learning y m√©tricas.
    * NLTK: Preprocesado de texto (stop words, lematizaci√≥n).
    * Gensim: Modelado de t√≥picos (Word2Vec).
    * Matplotlib y Seaborn: Visualizaci√≥n de datos.
    * WordCloud: Creaci√≥n de nubes de palabras.
* **Entorno:** Jupyter Notebook (desarrollado en Google Colab).

---

## üìÇ Estructura del Repositorio

```

.
‚îú‚îÄ‚îÄ Pr√°ctica\_final\_NLP\_Ulises\_Gonz√°lez.ipynb
‚îî‚îÄ‚îÄ README.md

````

---

## ‚öôÔ∏è Instalaci√≥n y Uso

Para ejecutar este proyecto localmente, sigue estos pasos:

1.  **Clona el repositorio:**
    ```bash
    git clone [https://github.com/tu-usuario/tu-repositorio.git](https://github.com/tu-usuario/tu-repositorio.git)
    cd tu-repositorio
    ```

2.  **Crea un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    ```

3.  **Instala las dependencias:**
    Crea un archivo `requirements.txt` con el siguiente contenido y luego ejecuta `pip install -r requirements.txt`.

    **Contenido para `requirements.txt`:**
    ```text
    pandas
    numpy
    requests
    matplotlib
    seaborn
    wordcloud
    nltk
    scikit-learn
    gensim
    jupyter
    ```

    **Comando de instalaci√≥n:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ejecuta el Notebook:**
    Inicia Jupyter Notebook y abre el archivo `Pr√°ctica_final_NLP_Ulises_Gonz√°lez.ipynb`.
    ```bash
    jupyter notebook
    ```
    Al ejecutar el notebook por primera vez, se descargar√°n autom√°ticamente los datos de Amazon y los paquetes necesarios de NLTK.

---

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles (si aplica).
````







